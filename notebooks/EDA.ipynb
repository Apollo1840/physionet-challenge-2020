{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmitriishubin/Desktop/physionet-challenge-2020\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics.metrics import Metric\n",
    "from kardioml.data.resample import Resampling\n",
    "\n",
    "from kardioml.data.p_t_wave_detector import PTWaveDetection\n",
    "\n",
    "metric = Metric()\n",
    "resampling = Resampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS = ['A','B','C','D','E','F']\n",
    "DATASETS = ['A','B','D','E'] #current for training\n",
    "#DATASETS = ['D']\n",
    "datalist = []\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    files = [i[:-4] for i in os.listdir(f'./data/{dataset}/formatted/') if i.find('.npy')!=-1]\n",
    "    for file in files:\n",
    "        datalist.append(f'./data/{dataset}/formatted/'+file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the length fits json and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tqdm(datalist):\n",
    "    signal = np.load(data+'.npy')\n",
    "    meta = json.load(open(data+'.json'))\n",
    "    \n",
    "    if meta['shape'][0] != signal.shape[0]:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the length distribution, all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = []\n",
    "exclusions = []\n",
    "exclusions_labels = []\n",
    "exclusions_digits = []\n",
    "\n",
    "for data in tqdm(datalist):\n",
    "    meta = json.load(open(data+'.json'))\n",
    "    if meta['labels_training_merged'] is None:\n",
    "        continue\n",
    "    if meta['shape'][0] > 38000:\n",
    "        file_name = data.split('/')     \n",
    "        exclusions.append(file_name[-1])\n",
    "        exclusions_labels.append(meta['labels_full'])\n",
    "        exclusions_digits.append(meta['labels_training_merged'])\n",
    "    length_list.append(meta['shape'][0])\n",
    "\n",
    "    \n",
    "sns.distplot(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.histogram(length_list,2000)\n",
    "plt.plot(hist[1][:-1][:100],hist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(length_list,99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check distribution of classes, calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32683/32683 [02:37<00:00, 207.99it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for data in tqdm(datalist):\n",
    "    meta = json.load(open(data+'.json'))\n",
    "    if meta['labels_training_merged'] is None:\n",
    "        meta['labels_training_merged'] = [0]*27\n",
    "    \n",
    "    label = meta['labels_training_merged']\n",
    "    if label[4] > 0 or label[18] >0:\n",
    "        label[4] = 1\n",
    "        label[18] = 1\n",
    "    if label[23] > 0 or label[12] >0:\n",
    "        label[23] = 1\n",
    "        label[12] = 1\n",
    "    if label[26] > 0 or label[13] >0:\n",
    "        label[26] = 1\n",
    "        label[13] = 1\n",
    "    labels.append(label)\n",
    "    \n",
    "\n",
    "    \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1. , 1. , 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.5,\n",
       "       0.5, 1. , 1. , 1. , 1. , 0.5, 1. , 1. , 1. , 1. , 0.5, 1. , 1. ,\n",
       "       0.5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_arr = np.array([1.]*27)\n",
    "weights_arr[[4,18,23,12,13,26]] = 0.5\n",
    "weights_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.750153846153845,\n",
       " 6.577333792628315,\n",
       " 149.171875,\n",
       " 70.45756457564576,\n",
       " 3.7990449661758854,\n",
       " 15.858803986710964,\n",
       " 11.742927429274292,\n",
       " 3.7104547221142634,\n",
       " 23.57283950617284,\n",
       " 104.91208791208791,\n",
       " 24.078184110970998,\n",
       " 63.85953177257525,\n",
       " 7.372200772200772,\n",
       " 49.21134020618557,\n",
       " 56.15882352941176,\n",
       " 156.50819672131146,\n",
       " 34.77959927140255,\n",
       " 55.50581395348837,\n",
       " 3.7990449661758854,\n",
       " 24.385696040868453,\n",
       " 27.99706744868035,\n",
       " 1.0,\n",
       " 16.89734513274336,\n",
       " 7.372200772200772,\n",
       " 8.066751161808195,\n",
       " 63.85953177257525,\n",
       " 49.21134020618557]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.sum(labels,axis=0)\n",
    "weights = weights/labels.shape[0]\n",
    "weights = weights[21]/weights\n",
    "#weights = weights / max(weights)\n",
    "weights = weights * weights_arr\n",
    "weights = weights.tolist()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking PT detector perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = np.arange(len(datalist))[0:11].tolist()\n",
    "\n",
    "datalist_sub = [i for index,i in enumerate(datalist) if index in data_range]\n",
    "\n",
    "\n",
    "for data in tqdm(datalist_sub):\n",
    "    meta = json.load(open(data+'.json'))\n",
    "    if meta['shape'][0] > 38000:\n",
    "        continue\n",
    "    elif meta['labels_training_merged'] is None:\n",
    "        continue\n",
    "    else:\n",
    "        signal = np.load(data+'.npy')\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        for i in range(12):\n",
    "            channel = signal[:,i]\n",
    "            plt.plot(channel+i*500)\n",
    "            plt.plot(meta['p_waves'][i],channel[meta['p_waves'][i]]+i*500,'*')\n",
    "            plt.plot(meta['t_waves'][i],channel[meta['t_waves'][i]]+i*500,'*')\n",
    "        plt.show()\n",
    "        plt.title(str(meta['labels_full'])+' | '+data)\n",
    "        print('===================')\n",
    "        print(data)\n",
    "        print(meta['labels_full'])\n",
    "        print('===================')\n",
    "        if data == '../data/A/formatted/A2091':\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking downsampling algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:00<00:00, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "./data/A/formatted/A3306\n",
      "['right bundle branch block']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A6853\n",
      "['sinus rhythm']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A3233\n",
      "['1st degree av block']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A3855\n",
      "['atrial fibrillation']\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [00:00<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "./data/A/formatted/A5826\n",
      "['1st degree av block']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A6747\n",
      "['right bundle branch block']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A0178\n",
      "['right bundle branch block']\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "./data/A/formatted/A5676\n",
      "['atrial fibrillation']\n",
      "===================\n",
      "===================\n",
      "./data/A/formatted/A3929\n",
      "['1st degree av block']\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_range = np.arange(len(datalist))[0:11].tolist()\n",
    "\n",
    "datalist_sub = [i for index,i in enumerate(datalist) if index in data_range]\n",
    "\n",
    "\n",
    "for data in tqdm(datalist_sub):\n",
    "    meta = json.load(open(data+'.json'))\n",
    "    if meta['shape'][0] > 38000:\n",
    "        continue\n",
    "    elif meta['labels_training_merged'] is None:\n",
    "        continue\n",
    "    else:\n",
    "        signal = np.load(data+'.npy')\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        for i in range(12):\n",
    "            channel = signal[:,i]\n",
    "            plt.plot(channel+i*500)\n",
    "            channel = resampling.downsample(channel,order=2)\n",
    "            plt.plot(channel+i*500)\n",
    "        plt.show()\n",
    "        plt.title(str(meta['labels_full'])+' | '+data)\n",
    "        print('===================')\n",
    "        print(data)\n",
    "        print(meta['labels_full'])\n",
    "        print('===================')\n",
    "        if data == '../data/A/formatted/A2091':\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of records without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6877/6877 [00:35<00:00, 192.96it/s]\n",
      "100%|██████████| 3453/3453 [00:19<00:00, 175.17it/s]\n",
      "100%|██████████| 516/516 [00:20<00:00, 25.57it/s]\n",
      "100%|██████████| 21837/21837 [01:19<00:00, 276.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#DATASETS = ['A','B','C','D','E','F']\n",
    "DATASETS = ['A','B','D','E'] #current for training\n",
    "#DATASETS = ['D']\n",
    "datalist_nones = []\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    files = [i[:-4] for i in os.listdir(f'./data/{dataset}/formatted/') if i.find('.npy')!=-1]\n",
    "    for file in tqdm(files):\n",
    "        meta = json.load(open(f'./data/{dataset}/formatted/'+file+'.json'))\n",
    "        if meta['labels_training_merged'] is None:\n",
    "            datalist_nones.append(meta['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json = {}\n",
    "dataset_json['data'] = datalist_nones\n",
    "\n",
    "json.dump(dataset_json, open(\"additional_data.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
